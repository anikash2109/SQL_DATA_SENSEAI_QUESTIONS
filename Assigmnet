1: select festival_name, country, ticket_type
from festivaldata

2:select festival_name,
        city,
        date
from festivaldata 
where country = 'usa'

3: select festival_name,
        ticket_type,
        price 
from festivaldata
where price>100 and country='India'

4:select festival_name,
        country,
        ticket_type
from festivaldata 
where country= 'India' or country='USA'

5: select sum(price) as total_revenue,
ticket_type
from festivaldata 
group  by ticket_type


6:select festival_name,
        max(price)
from festivaldata 
group by festival_name 
order by max(price) desc
limit 5


7:select festival_name,
        price 
from festivaldata 
order by price desc
limit 5 offset 5



8:select festival_name,
 sum(organizer_profit) as total_profit
 from festivaldata 
 where country = 'India' 
 group by festival_name
 having sum(price)>100



9:select country,
    max(organizer_profit) as max_profit 
from festivaldata
group by country



10:select ticket_type,
        sum(organizer_profit) as total_profit
from festivaldata
where country = 'India' or country='USA'
group by ticket_type
having avg(price)> 50



11:select movie_name,
        avg(rating) as rating 
from user_watch_activity 
group by movie_name
order by avg(rating) desc
limit 5 offset 3



12:select user_name,
    watch_time_minutes 
from user_watch_activity 
where watch_time_minutes between 100 and 150





13:select user_name,
        watch_time_minutes as total_watch_time
from user_watch_activity
where genre = 'Sci-fi'
order by watch_time_minutes asc
limit 1



14:select genre,
        watch_time_minutes as total_watch_time 
from user_watch_activity 
where country = 'japan'
order by total_watch_time desc
limit 1



15:select user_name,
    total_movies_watched
from user_watch_activity 
where  subscription_type = 'Premium'
order by total_movies_watched desc
limit 5



16:select transaction_id,
        customer_name,
        transaction_value 
from payment_transactions 
order by transaction_value desc
limit 5



17:SELECT 
    product_category,
    SUM(quantity_purchased * price_per_unit) AS revenue_before_discount,
    SUM(transaction_value) AS revenue_after_discount
FROM 
    payment_transactions
GROUP BY 
    product_category;





 18:select distinct payment_method,
        avg(transaction_value)
from payment_transactions
group by payment_method
order by avg(transaction_value) desc
limit 1



19:select customer_name,
        sum(transaction_value),
        case 
        when sum(transaction_value) > 2000 then 'High Spend'
        when sum(transaction_value) between 1000 and  2000 then 'Medium Spend'
        when sum(transaction_value) < 1000 then 'Low Spend'
        end total_spending 
from payment_transactions 
group  by customer_name



20:select customer_name,
        round(avg(customer_rating),2) as avg_rating
from payment_transactions 
group by customer_name 
having avg(customer_rating)<4



21: select product_name,
        product_category,
        likes_count
from amazereviews 
where likes_count> 100 and (discount_applied)<10
and (review_rating = 4 or review_rating = 5)
 



22:select product_name,
        review_rating,
        delivery_days,
        discount_applied 
from amazereviews 
where (review_rating=1 or review_rating=2)
and (delivery_days>7 or discount_applied<5)



23:select review_id,
        reviewer_name,
        review_text 
from amazereviews 
where review_text like 'great%' and review_text like '%perfectly%'



24:select distinct product_name,
        product_category
from amazereviews 
where product_name like '_l_____'



25:select product_name,
        product_price,
        likes_count
from amazereviews 
where (product_price not between 50 and 200) and
likes_count> 100



26:select product_name,
        review_rating,
        delivery_days
from amazereviews 
where (review_rating = 4 or review_rating=5) and
(verified_purchase = 'Y') and 
(delivery_days<=5)



27:select product_name,
        product_category
from amazereviews 
where product_name like 'S_________'



28:select review_id,
        reviewer_name,
        review_text 
from amazereviews 
where (review_text like 'G%' and review_text like '%price%' )and 
 (review_text like '%_____quality%')



29: select distinct product_name,
        review_text,
        product_price,
        review_rating
from amazereviews 
where (review_text not like '%great%' or review_rating not like '%good%')
and (product_price not between 10 and 100)
and (review_rating=1 or review_rating=2)



30:select review_id,
        product_name,
        review_text,
        product_price,
        likes_count 
from amazereviews 
where (review_text like '%word%' or review_text like 'A%')
and (product_price between 20 and 200)
and (review_text not like '%poor%')
and (likes_count>50)



31:select room_type,
        sum(total_amount) as total_revenue 
from hotelbookings 
group by room_type 
order by total_revenue desc



32:select 
        case
        when breakfast_included = 1 then 'with  breakfast'
        when breakfast_included = 0 then 'without breakfast'
        end breakfast_option,
        avg(feedback_score ) as average_feedback
from hotelbookings 
group by breakfast_option



33: select guest_name,
        max(total_amount) as total_amount,
        membership_level
from hotelbookings
group by guest_name,membership_level 
order by max(total_amount) desc
limit 5



34:select count(booking_id) as number_of_bookings,
        membership_level 
from hotelbookings 
group by membership_level



35:select city,
        sum(total_amount) as total_revenue       (Not got Correct on website just code)
from hotelbookings
where feedback_score>=7 and (total_guests<2)
group by city 
having count(booking_id)=3
order by total_revenue desc




36:select city,
    sum(total_amount) as total_revenue,
    guest_name 
from hotelbookings 
where membership_level = 'platinum'
group by city, guest_name



37:select city,
        sum(total_amount) as total_Strict_Revenue,
        count(booking_id) as booking_count,
        case 
        when sum(total_amount)>40000 then 'High Revenue'     (Not got Correct on website just code)
        else 'Low Revenue'
        end revenue_category
from hotelbookings 
where cancellation_policy = 'strict'
group by city 
having count(booking_id) = 2



38:select membership_level,
        avg(feedback_score) as avg_feedback,
        case 
        when avg(feedback_score)>=9 then 'Excellent Feedback'
        when avg(feedback_score)between 7 and 9 then 'Good Feedback'    (giving me incorrect/ output is correct)
        when avg(feedback_score)<7 then 'Needs Improvement'
        end feedback_category
from hotelbookings 
group by membership_level
having count(booking_id)>=5 
order  by avg(feedback_score) desc


39: select 
case 
when total_guests between 1 and 2 then 'Small group'
when total_guests between 3 and 4 then 'Medium group'
when total_guests >5  then 'Large group'
end group_category,
sum(total_amount) as total_revenue,
sum(total_amount)*100/(select sum(total_guests) from hotelbookings) as reveue_percentage
from hotelbookings
group by 
        case
        when  total_guests between 1 and 2 then 'Small group'
        when total_guests between 3 and 4 then 'Medium group'
        when total_guests >5  then 'Large group'
    end 
having reveue_percentage>30
order by total_revenue desc



40:select city,
        membership_level,
        sum(total_amount) as membershiprevenue,
sum(total_amount)*100/(select sum(total_amount) from hotelbookings as a
where a.city=hotelbookings.city) as contribution,
case 
when sum(total_amount)*100/(select sum(total_amount) from hotelbookings as a
where a.city=hotelbookings.city) > 50 then 'High contributor'
when sum(total_amount)*100/(select sum(total_amount) from hotelbookings as a
where a.city=hotelbookings.city) between 25 and 50 then 'moderate contributor'
when sum(total_amount)*100/(select sum(total_amount) from hotelbookings as a
where a.city=hotelbookings.city) < 25 then 'Low contributor'
end as loyalty
from hotelbookings 
group by city,membership_level
having 
case 
when sum(total_amount)*100/(select sum(total_amount) from hotelbookings as a
where a.city=hotelbookings.city)>50 then 'High Contributor'
when sum(total_amount)*100/(select sum(total_amount) from hotelbookings as a
where a.city=hotelbookings.city) between 25 and 50 then 'Moderate contributor'
when sum(total_amount)*100/(select sum(total_amount) from hotelbookings as a
where a.city=hotelbookings.city)<25 then 'Low contributor'
end in('High Contributor', 'Moderate contributor')









41: select book_title, 
        sum(sales_amount) as sales_amount,
        sum(sales_count) as sales_count,
        publisher
from bookreviews 
where (book_title like '%Love%' or book_title like '%Heart%') 
group by book_title, publisher
having sum(sales_amount)>3000 and 
sum(sales_count)>100



42:select genre,
        avg(rating) as avg_rating,
        sum(sales_amount)
from bookreviews 
where genre like 'R%'
group by genre 
having avg(rating)>=4



43:select author_name, 
        sum(sales_count)
from bookreviews 
where review_text like '%Masterpiece%'
group by author_name
having sum(sales_count)>150
order by sum(sales_count) desc



44:select publisher,
    sum(sales_amount),
    sum(sales_count)
from bookreviews 
where (review_text like '%Fantastic%' or review_text like '%Thrilling%')
group by publisher
having sum(sales_amount)>3000 and 
sum(sales_count)>100
order by sum(sales_amount) desc



45:select book_title,
        genre,
        sum(sales_amount),
        avg(rating) as avg_rating 
from bookreviews 
where genre = 'Science' and 
(review_text  like '%plot%' or review_text like '%inspiring%')
group by genre, book_title
having sum(sales_amount)>3000



46:select membership_type,
        sum(session_revenue),
        case
        when sum(session_revenue)>300 then 'High Revenue'
         when sum(session_revenue) between 150 and 300 then 'Medium Revenue'
        else 'Low Revenue'
        end Revenue_category
from workoutanalytics 
group by membership_type



47:select session_type,
        avg(workout_duration) as avg_duration,
        avg(calories_burned) as avg_calories, 
        case 
        when avg(workout_duration)>75 then 'High Intensity'
        when avg(workout_duration) between 45 and 75 then 'Medium Intensity'
        else 'low intensity'
        end intensity_level 
from workoutanalytics 
group by session_type 




48:select trainer_session,
        avg(satisfaction_rating) as avg_satisfaction,
        case
        when avg(satisfaction_rating)>= 4.5 then 'Excellent'
        when avg(satisfaction_rating) between 3.5 and  4.5 then 'Good'
        else 'Needs Improvement'
        end rating_quality 
from workoutanalytics
group by trainer_session



49:select workout_id,
        session_type,
        workout_duration,
        session_revenue,
        case 
        when session_revenue>40 and workout_duration>60 then 'High Value'
        else 'Regular Value'
        end value_category
from workoutanalytics 



50:select trainer_session,
        sum(calories_burned) as total_calories,
        count(session_type) as  total_sessions,
        case 
        when sum(calories_burned) > 4000 then 'High Impact'
        when sum(calories_burned) between 2000 and 4000 then 'Medium Impact'
        else 'Low impact'
        end trainer_impact 
from workoutanalytics
where trainer_session = 'Y' 
group by trainer_session 




51:select date(order_delivered_timestamp),
       count(order_id) as  total_deliveries 
from deliverydash
group by date(order_delivered_timestamp)
order by count(order_id) desc 
limit 1



52: select delivery_agent,
        avg(minute(actual_delivery_time)) as delivery_time    (Not sure, Not Correct)   
from deliverydash 
group by delivery_agent 
order by avg(minute(actual_delivery_time)) desc 
limit 3

(SELECT 
    Delivery_Agent, 
    AVG(TIME_TO_SEC(Actual_Delivery_Time)) / 60 AS Average_Delivery_Time_Minutes     (correct querry)
FROM 
    DeliveryDash
GROUP BY 
    Delivery_Agent
ORDER BY 
    Average_Delivery_Time_Minutes DESC
LIMIT 3;)



53:select date(order_delivered_timestamp),
 sum(order_amount) as total_revenue
from deliverydash 
group by date(order_delivered_timestamp)
having sum(order_amount)>50



54:select city,
    max(order_delivered_timestamp) as latest_delivery_time,
    min(order_delivered_timestamp) as earliest_delivery_time
from deliverydash 
group by city 



55:SELECT SUM(Order_Amount) AS Total_Revenue
FROM deliverydash
WHERE EXTRACT(HOUR FROM Order_Delivered_Timestamp) BETWEEN 18 AND 22;







56: select date(order_delivered_timestamp) as delivery_date,
        sum(order_amount) as total_revenue 
from deliverydash 
group by date(order_delivered_timestamp)
order by sum(order_amount) desc
limit 1



57:select order_id,
        customer_name,
        order_delivered_timestamp,
        city 
from deliverydash 
where dayofweek(order_delivered_timestamp) in (1,7)



58:select delivery_agent,
sum(timestampdiff(minute, order_placed_timestamp, order_delivered_timestamp))
from deliverydash
group by delivery_agent





59:select order_id,
        customer_name,
        order_placed_timestamp,
        city 
from deliverydash 
where order_placed_timestamp>= date_sub('2024-06-30', interval 7 day)




60:select count(order_id),
        hour(order_delivered_timestamp)
from deliverydash 
group by hour(order_delivered_timestamp)
order by hour(order_delivered_timestamp) asc



61: SELECT 
    student_name,
    course_name,
    exam_date,
    DATEDIFF(exam_date, '2024-06-10') AS Days_Until_Exam
FROM 
    edutrack;




62:select student_name,
        course_name,
        attendance_date,
        assignment_submission_date
from edutrack 
where assignment_submission_date> attendance_date - interval 2 day



63:select date_format(attendance_date, '%Y-%m') as month,
        count(attendance_id) as total_attendance
from edutrack 
where attendance_status='Present'
group by date_format(attendance_date, '%Y-%m')





64:select student_name,
       exam_score,
        case
        when exam_score>=85 then 'High'
        when exam_score between 70 and 84 then 'Medium'
        when exam_score<70 then 'Low'
        end performance_tier 
from edutrack 




65:select Student_Name, Course_Name,
Assignment_Submission_Date, Exam_Date,
Datediff(exam_date , Assignment_Submission_Date)
from edutrack
where Assignment_Submission_Date = Date_sub(exam_date , interval 12 Day);



66: SELECT
    train_name,
    scheduled_departure,
    actual_departure,
    FLOOR(TIMESTAMPDIFF(MINUTE, scheduled_departure, actual_departure) / 60) AS delay_hours,                (complete help)
    MOD(TIMESTAMPDIFF(MINUTE, scheduled_departure, actual_departure), 60) AS delay_minutes
FROM
    train_schedule
where actual_departure > scheduled_departure ;



67:select train_name,
        scheduled_departure,
        actual_departure,
        scheduled_arrival,                                        (just where clause comparisons)
        actual_arrival 
from train_schedule 
where (actual_departure>scheduled_departure) and 
actual_arrival<scheduled_arrival




68:    select train_name,
        scheduled_departure,
        reschedule_time 
    from train_schedule
    where reschedule_time is not null and 
    timestampdiff(minute,scheduled_departure,reschedule_time)<=30                        (Help)












69:SELECT 
    maintenance_day,
    ROUND(AVG(TIMESTAMPDIFF(MINUTE, scheduled_departure, actual_departure)), 2) AS avg_delay_minutes
FROM train_schedule
WHERE DAYOFWEEK(date_of_journey) IN (1, 7)  and                         (help)
 -- 1 = Sunday, 7 = Saturday
GROUP BY maintenance_day
ORDER BY FIELD(maintenance_day, 'Monday', 'Tuesday', 'Thursday', 'Sunday', 'Friday', 'Saturday');



70:SELECT train_name,
        scheduled_departure,
        actual_departure,
        TIMESTAMPDIFF(minute,scheduled_departure,actual_departure) 
FROM train_schedule
WHERE TIMESTAMPDIFF(MINUTE, scheduled_departure, actual_departure) % 15 = 0;




71: SELECT 
    train_name,
    passenger_count,                                                (ChatGpt)
    date_of_journey
FROM 
    train_schedule
WHERE 
    cancelled_flag = 1
    AND passenger_count > 200
    AND DAYOFWEEK(date_of_journey) BETWEEN 2 AND 6; -- Monday (2) to Friday (6)






81:select model_name,
        active_users_thousand
from llm_development
where active_users_thousand<(select active_users_thousand
from llm_development where inference_speed_tokens_per_sec=(select max(inference_speed_tokens_per_sec) from llm_development))




82: select model_name,
       training_duration_days 
from llm_development 
where training_duration_days>
 (select min(training_duration_days) from llm_development
 where fine_tuned=1)




83:select model_name,
       usage_count_million
from llm_development 
where  usage_count_million>(select avg(usage_count_million)*2 from llm_development
where model_status = 'Retired')



84: select model_name,
        training_data_size_gb
from llm_development 
where training_data_size_gb<(select avg(training_data_size_gb)from llm_development
where year(release_date)='2023')



85:select model_name,
        training_data_size_gb
from llm_development 
where training_data_size_gb<(select max(training_data_size_gb)
from llm_development where year(release_date)='2023')


86:select model_name,
        accuracy_percent,
        training_duration_days
from llm_development 
where accuracy_percent>90 and 
training_duration_days<(select avg(training_duration_days) from llm_development)




87:select model_name,
        training_data_size_gb
from llm_development 
where training_data_size_gb>(select avg(training_data_size_gb)
from llm_development where year(release_date)<'2022')



88:select model_name,
        inference_speed_tokens_per_sec
from llm_development 
where inference_speed_tokens_per_sec<(select inference_speed_tokens_per_sec 
 from llm_development where parameters_in_billion=(select min(parameters_in_billion) from llm_development))



89:select model_name,
        accuracy_percent
from llm_development 
where accuracy_percent> all (select accuracy_percent from 
llm_development where year(release_date)='2021')




90:SELECT model_name,
       training_duration_days
FROM llm_development
WHERE training_duration_days > (
    SELECT (MIN(training_duration_days) + MAX(training_duration_days)) / 2
    FROM llm_development
    WHERE fine_tuned = 1
);



91:select team_name,
       win_rate_percent 
from esports_tournament 
where win_rate_percent >(select avg(win_rate_percent)
from esports_tournament where tournament_name = 'World Cup')




92:select team_name,
        game_title,
        prize_pool_usd 
from esports_tournament as a
where prize_pool_usd =(select max(prize_pool_usd)
from esports_tournament as b where a.game_title=b.game_title)






93:select team_name,
        participation_fee_usd
from esports_tournament
where participation_fee_usd> all(select avg(participation_fee_usd)
from esports_tournament)




94:select team_name,
        game_title,
        team_ranking 
from esports_tournament as a
where team_ranking in(select min(team_ranking)
from esports_tournament as b where a.game_title=b.game_title)






95:select team_name,
        matches_won
from esports_tournament 
where matches_won<(select sum(matches_played)-sum(matches_won) from
esports_tournament)




96:select team_name,
        total_kills,
        region
from  esports_tournament as a 
where total_kills>all(select avg(total_kills *1.5)
from esports_tournament)






97: select team_name,
    game_title,
    region,
    win_rate_percent 
from esports_tournament as a
where win_rate_percent>(select avg(win_rate_percent)
from esports_tournament as b
where a.game_title=b.game_title and 
a.region=b.region)




98:select team_name,
        game_title,
        avg_match_duration_minutes
from esports_tournament as a                           (chat Gpt)
where avg_match_duration_minutes>
(select min(avg_match_duration_minutes) from
esports_tournament as b where team_ranking<5
and a.game_title=b.game_title )




99:SELECT team_name,
       tournament_name,                                 (chat gpt)
       total_deaths
FROM esports_tournament AS a
WHERE total_deaths > (
    SELECT AVG(total_kills)
    FROM esports_tournament AS b
    WHERE a.tournament_name = b.tournament_name
);




100: select team_name,
    Region,
    matches_won,
    win_rate_percent,
    participation_fee_usd 
from esports_tournament 
where (matches_won<5) and 
(win_rate_percent<40) and (participation_fee_usd>3000) and 
(Region='NA' or Region='EU')




101:select comment_id,
        user_name,
        substring(comment_text, 1,10 ) as preview_text 
from socialhub_comments 



102: select comment_id,
        user_name,
        comment_text
from socialhub_comments
where comment_text like '%the%'




103:select comment_id,
        user_name,
        substring_index(mentions, '@', -1)
from socialhub_comments
where substring_index(mentions, '@', -1) is not null




104: select comment_id,
        user_name,
        reverse(comment_text)
from socialhub_comments 
where sentiment='Negative'





105: select comment_id,
       replace(mentions, '@', '(at)')
from socialhub_comments 



106:select comment_id,
       hashtags
from socialhub_comments 
where hashtags regexp'work'



107: select substring_index(email, '@', -1),
count(distinct(user_name))
from socialhub_comments
group by substring_index(email,'@', -1)




108:select substring_index(email, '@', -1),
count(distinct(user_name))
from socialhub_comments
group by substring_index(email, '@', -1)





109:  select comment_id,
user_name,
substring(replace(replace(replace(replace(replace(reverse
(comment_text),'a', '*'),'e','*'),'i', '*'),'o','*'),'u','*'),1,20)
from socialhub_comments
where platform='Instagram'



110:select user_name,
        email
from socialhub_comments 
where user_name not like'%a%'








111:select year(concert_date) as concert_year,
        month(concert_date) as concert_month,
        sum(revenue) 
from global_concert_tour 
where concert_date>= last_day(concert_date)- interval 4 day and       (chatGpt) 
concert_date <= last_day(concert_date)
group by year(concert_date),
        month(concert_date)




112: SELECT 
    YEAR(concert_date) AS concert_year,
    MONTH(concert_date) AS concert_month,                        (chatgpt)
    AVG(tickets_sold) AS avg_tickets_sold
FROM 
    global_concert_tour
WHERE 
    DAY(concert_date) BETWEEN 1 AND 7
GROUP BY 
    YEAR(concert_date),
    MONTH(concert_date);


113:select year(concert_date),
    monthname(concert_date),
    month(concert_date),
    case 
    when day(concert_date) <=15 then 'first half'
    else 'second half'
    end as interval_period,
    sum(revenue)
from global_concert_tour
group by year(concert_date), monthname(concert_date),month(concert_date), interval_period
order by month(concert_date),sum(revenue) asc



114:select year(concert_date),
        case
        when month(concert_date) between 1 and 3 then 1
        when month(concert_date) between 4 and 6 then 2
        when month(concert_date) between 7 and 9 then 3
        when month(concert_date) between 10 and 12 then 4 
        end as concert_quater,
        sum(revenue) as total_revenue 
from global_concert_tour 
group by year(concert_date), concert_quater




115: select year(concert_date),
        monthname(concert_date),
        singer,
        location,
        concert_date,
        revenue
from global_concert_tour
where weekday(concert_date) in (5,6)




116: select year(concert_date),
        monthname(concert_date),
        month(concert_date),
        sum(revenue)
from global_concert_tour 
where concert_date>= last_day(concert_date)- interval 10 day 
group by year(concert_date),
        monthname(concert_date),
        month(concert_date)
order by month(concert_date)




117:select year(concert_date),
        monthname(concert_date),
        avg(revenue)
from global_concert_tour 
where concert_date> last_day(concert_date)-interval 5 day 
group by year(concert_date),monthname(concert_date)
order by year(concert_date), monthname(concert_date)



118: SELECT 
    YEAR(concert_date) AS year,
    MONTHNAME(concert_date) AS month_name,
    MONTH(concert_date) AS month,
    SUM(CASE WHEN DAY(concert_date) BETWEEN 1 AND 15 THEN revenue ELSE 0 END) AS first_half,
    SUM(CASE WHEN DAY(concert_date) >= 16 THEN revenue ELSE 0 END) AS second_half,
    CASE 
        WHEN SUM(CASE WHEN DAY(concert_date) BETWEEN 1 AND 15 THEN revenue ELSE 0 END) = 0                      (Needed some help)
        THEN NULL  -- Avoid division by zero
        ELSE 
            ((SUM(CASE WHEN DAY(concert_date) >= 16 THEN revenue ELSE 0 END) - 
              SUM(CASE WHEN DAY(concert_date) BETWEEN 1 AND 15 THEN revenue ELSE 0 END)) 
             / SUM(CASE WHEN DAY(concert_date) BETWEEN 1 AND 15 THEN revenue ELSE 0 END)) * 100
    END AS percentage_change
FROM global_concert_tour
GROUP BY 
    YEAR(concert_date), 
    MONTHNAME(concert_date), 
    MONTH(concert_date);




119:SELECT 
    YEAR(concert_date), 
    monthname(concert_date),
    month(concert_date),
avg(case when dayofweek(concert_date) in (2,3,4,5,6) then revenue
else null end) as weekday_revenue,                                                        (Got logic with help)
avg(case when dayofweek(concert_date) in (1,7) then revenue
else null end) as weekend_revenue
from global_concert_tour 
where concert_date >= last_day(concert_date)-interval 9 day and
concert_date<= last_day(concert_date)
    group by YEAR(concert_date), 
    monthname(concert_date),
    month(concert_date)
order by month(concert_date)

    


120:select year(concert_date),
        month(concert_date),
        singer,
        sum(revenue),
        sum(revenue)*100/(select sum(revenue) from global_concert_tour)
from global_concert_tour 
group by year(concert_date),
        month(concert_date),
        singer



121:select battle_name,
        attendance_capacity 
from battles 
where attendance_capacity=(select max(attendance_capacity) from battles)



122: select battle_name,
        Reenactment_Start_Date
from battles 
where month(Reenactment_Start_Date)= (select month(Reenactment_Start_Date)
from battles where budget =(select max(budget) from battles)
and year(Reenactment_Start_Date) = (select year(Reenactment_Start_Date) from 
battles where budget =(select max(budget) from battles)






123:select battle_name,
        budget 
from battles 
where budget >(select avg(budget) from battles)



124:SELECT Location, 
SUM(Budget) AS Total_Budget
FROM battles
GROUP BY Location
HAVING SUM(Budget) = (
    SELECT MAX(Total_Budget)
    FROM (
        SELECT SUM(Budget) AS Total_Budget                        (Help from satvik sir )
        FROM battles
        GROUP BY Location
    ) AS Location_Budgets
);




125:select battle_name,
       weather_condition 
from battles as a
where weather_condition in(select weather_condition
from battles where budget=(select max(budget) from
battles))




126:select battle_name,
        max(attendance_capacity)
from battles 
group by battle_name
order by max(attendance_capacity) desc
limit 1 offset 1




127:select battle_name,
     max(day(Reenactment_End_Date)-day(Reenactment_start_Date)) as duration
from battles
group by battle_name
order by max(day(Reenactment_End_Date)-day(Reenactment_start_Date)) desc
limit 1





128:select battle_name,
        min(budget)
from battles 
group by battle_name
order by min(budget)
limit 1 offset 1





129: SELECT 
    DATEDIFF(Reenactment_Start_Date, LAG(Reenactment_Start_Date) OVER (ORDER BY Reenactment_Start_Date)) AS Gap_In_Days
FROM 
    battles
ORDER BY 
    Gap_In_Days DESC
LIMIT 1;





130:




131: select post_id,
    replace(substring_index(hashtags,'#', 2),',','')
from social_posts



132:select post_id,
length(mentions)-length(replace(mentions,',', ''))+1
from social_posts







133:SELECT 
    user_name,
    (likes + shares) AS engagement,
    round((likes + shares) * 100.0 / 
    (SELECT SUM(likes + shares) FROM social_posts),4) 
    AS engagement_rate
FROM 
    social_posts
order by engagement_rate desc 



134:SELECT 
    COUNT(CASE WHEN Sentiment = 'Positive' THEN 1 END) * 100.0 / COUNT(*) AS positive_percentage
FROM 
    social_posts;




135:select post_id,
     post_content
from social_posts
group by post_id
having max(length(regexp_substr(post_content,'[a-zA-z]+'))) 
order by  max(length(regexp_substr(post_content,'[a-zA-z]+'))) desc                        (just got the help of regexxp function through chatgpt)
limit 1



136:select book_title,
    sum(quantity_sold)
from bookstore_sales 
group by book_title  
having sum(quantity_sold) in(select max(quantity_sold) from bookstore_sales    (chatgpt a little help)
)





137: select book_title,
        genre 
from bookstore_sales
where genre in (select 
genre from bookstore_sales 
group by genre 
having count(*)= 1)



138: SELECT 
    Book_Title,
    COUNT(DISTINCT Customer_Location) AS Unique_Cities
FROM 
    bookstore_sales
GROUP BY 
    Book_Title
ORDER BY 
    Unique_Cities DESC
LIMIT 1;



139: SELECT 
    author_name,
    SUM(quantity_sold) AS total_books_sold,
    SUM(quantity_sold) * 100.0 / (SELECT SUM(quantity_sold) FROM bookstore_sales) AS percentage_contribution
FROM 
    bookstore_sales
GROUP BY 
    author_name
ORDER BY 
    total_books_sold DESC;



140: select book_title
from bookstore_sales 
where length(customer_review)>                    (chatGpt)
(select avg(length(customer_review))
from bookstore_sales 
where customer_review is not null)



141:SELECT 
    book_title,
    author_name
FROM 
    bookstore_sales
WHERE 
    author_name IN (
        SELECT                                 (chatgpt)
            author_name
        FROM 
            bookstore_sales
        GROUP BY 
            author_name
        HAVING 
            COUNT(DISTINCT sale_date) >= 3
    );




142:select author_name,
        date_format(sale_date, '%Y-%m')
from bookstore_sales
group by author_name,date_format(sale_date, '%Y-%m')
having count(week(sale_date))>=2


143:
144:





145:select author_name,
        date_format(sale_date,'%Y-%m'),
        total_revenue 
from bookstore_sales 
where author_name in (select author_name 
from bookstore_sales where total_revenue in(select 
max(total_revenue) from bookstore_sales
where sale_date >= last_day(sale_date)- interval 7 day ))



146:

147:select post_id ,
length(hashtags) - length(replace(hashtags,',','')) + 1 as count     (chatgpt/ aayush)
from indian_influencers
group by post_id ;



148:select  distinct influencer_name,
       count(distinct(category)) 
from indian_influencers 
group by  influencer_name
order by count(distinct(category)) desc
limit 3



149:





150:SELECT DISTINCT Influencer_Name
FROM indian_influencers AS outer_table
WHERE NOT EXISTS (
    SELECT 1
    FROM indian_influencers AS inner_table
    WHERE inner_table.Influencer_Name = outer_table.Influencer_Name
    AND inner_table.Sentiment != 'Positive'
);



151: select post_id,
    replace(substring_index(hashtags, '#', 2),',', '')
from indian_influencers 




152:SELECT 
    post_id,
    LENGTH(post_content) - LENGTH(REPLACE(post_content, ' ', '')) + 1 AS word_count
FROM 
    indian_influencers;



153:         SELECT 
    post_id, 
    post_content
FROM 
    indian_influencers
WHERE 
    POSITION('exclusive' IN post_content) ;



154:select post_id,
    replace(hashtags,'#', 'HASHTAG-')
from indian_influencers




155:


156:  select post_id,
        concat(
upper(substring(post_content,1,1)
lower(substring(post_content, 2)
) as capitalize_each_word
from indian_influencers 


157: select post_id,
        reverse(post_content)
from indian_influencers 



158: 




159:SELECT 
    sentiment,
    AVG(LENGTH(post_content)) AS avg_sentiment_length
FROM indian_influencers 
GROUP BY sentiment



160:select post_id, 
  rpad(post_content, 100, '*')
from indian_influencers  




161: select post_id,
        post_content 
from indian_influencers 
where left(post_content,position(' ', post_content) -1) = right(post_content, position(' ', reverse(post_content)-1)








162:select post_id,
        substring_index(hashtags, ',', -1)
from indian_influencers 



163:select post_id,
        hashtags 
from indian_influencers 




164:select post_id,
    replace(post_content, ' ', '_')
from indian_influencers 




165:select post_id,
        substring_index(brand_tags, ',', -1)
from indian_influencers
where brand_tags <> ''



166:select region,
        sum(revenue_millions)
from ai_startups
where founded_year> 2015
group by region
order  by sum(revenue_millions) desc
limit 1




167:select top_investor,
     sum(total_funding_millions)
from ai_startups                                                        (just needed help regarding type of question)
where annual_growth_rate >(select avg(annual_growth_rate)
from ai_startups)
group by top_investor
order by sum(total_funding_millions) desc
limit 1




168: select region,
avg(total_funding_millions/founders_count) as k
from ai_startups 
group by region
order by k desc
limit 1




169: select startup_name,
    total_funding_millions,
    funding_stage 
from ai_startups  as a                                        (just needed to filter on the funding stage as given in  the question)                                                                                
where industry = 'Healthcare' and 
total_funding_millions>(select avg(total_funding_millions)
from ai_startups as b 
where a.funding_stage=b.funding_stage)



170:         SELECT 
    region,
    COUNT(*) AS startup_count
FROM 
   ai_startups
WHERE                                                                 (took help)
    (Revenue_Millions / Total_Funding_Millions) > 2
GROUP BY 
    region
ORDER BY 
    startup_count DESC;


171:




172: 

173:select industry
from(                                                        (Just needed sum agg help)
select industry,
sum(case
    when funding_stage = 'Seed' then 1 else 0 end)/Count(*)*100 
from ai_startups 
group by industry
having sum(case
    when funding_stage = 'Seed' then 1 else 0 end)/Count(*)*100 >40 and
sum(total_funding_millions)>100) as b


174:select founded_year,
        avg(annual_growth_rate)
from ai_startups 
where profitability = 1 and 
(employees)>100
group by founded_year
order by avg(annual_growth_rate) desc
limit 1



175:select top_investor,
    sum(total_funding_millions)
from ai_startups 
where founded_year>2010
group by top_investor
order by sum(total_funding_millions) desc
limit 5




176: SELECT industry
FROM (
    SELECT 
        industry,
        SUM(CASE WHEN profitability = 1 AND rating > 4.5 THEN 1 ELSE 0 END) * 100.0 / COUNT(*) AS percent  (Help chatgpt)
    FROM ai_startups
    GROUP BY industry
) AS bb
WHERE percent > 70;




177:select region,
avg(revenue_millions/employees)
from ai_startups 
where founded_year>2015
group by region 
order by avg(revenue_millions/employees) desc
limit 1



178:SELECT 
    industry,
    sum(CASE WHEN profitability = 1 THEN total_funding_millions ELSE 0 end)-
    sum(CASE WHEN profitability = 0 THEN total_funding_millions ELSE 0 END) as aniket 

FROM 
    ai_startups
GROUP BY 
    industry
order by aniket desc
limit 1


179: 

180:select founded_year,
        revenue_growth
from(
SELECT 
    industry, 
    founded_year,
    (currentt - coalesce(previous,0)) AS revenue_growth,
    dense_rank() OVER (PARTITION BY industry ORDER BY currentt - previous DESC) AS rnkk
FROM (
    SELECT 
        industry,
        founded_year,
        SUM(revenue_millions) AS currentt,
        LAG(SUM(revenue_millions)) OVER (PARTITION BY industry ORDER BY founded_year) AS previous
    FROM 
        ai_startups
    GROUP BY 
        industry, founded_year
) AS a) as b 
where rnkk=3 and founded_year=2016
limit 1;



181: select transaction_year,
        sum(revenue)
from credit_card_performance 
where card_type = 'Premium'
group by transaction_year
order by sum(revenue) asc
limit 1




182: select region, 
(SUM(CASE WHEN Default_Flag = 1 THEN 1 ELSE 0 END) * 1.0/ COUNT(*)) * 100 AS default_rate
                                                                                                (Help from chatgpt regarding the )
    from credit_card_performance
where card_type= 'Business'
group by region



183: SELECT 
    region,
    transaction_quarter,
    total_profit
FROM (
    SELECT 
        region,
        transaction_quarter,
        SUM(profit) AS total_profit,
        RANK() OVER (PARTITION BY region ORDER BY SUM(profit) DESC) AS rankk                        (Best window problem)
    FROM 
        credit_card_performance
    GROUP BY 
        region, transaction_quarter
) AS ranked_data
WHERE 
    rankk = 1
ORDER BY 
    region ASC;




184: SELECT 
    region,
    transaction_quarter, 
    round((SUM(loss_provision) / SUM(revenue) * 100), 8) AS loss_provision_percentage
FROM 
    credit_card_performance
GROUP BY 
    region, transaction_quarter
ORDER BY 
    loss_provision_percentage DESC;



185:Select card_type,Transaction_Year,yoy_profit_growth from 
(Select card_type,                                                         (Easy just steps are more)
Transaction_Year, 
(total_profit- coalesce(previous_year_profit,0)) as yoy_profit_growth, 
rank() over(partition by card_type order by (total_profit- coalesce(previous_year_profit,0)) desc ) as rnk from 
(Select card_type, 
Transaction_Year, 
sum(profit) as total_profit,
lag(sum(profit)) over( partition by card_type order by Transaction_Year) as previous_year_profit
from credit_card_performance group by card_type, Transaction_Year ) as a) as b where rnk=1 
order by yoy_profit_growth ;



186:select transaction_year,
        sum(transactions_count)
from credit_card_performance
group by transaction_year
order by sum(transactions_count) desc
limit 1



187:select card_type,
sum(profit)
from  credit_card_performance 
group by card_type
order by sum(profit) desc
limit 2



188:

189:






190:SELECT customer_id, 
       SUM(outstanding_balance) OVER (PARTITION BY customer_id) AS total_balance_growth   (Got the idea from youtube and gpt)
FROM credit_card_performance -- Filter last 3 years dynamically
ORDER BY total_balance_growth DESC
limit 3;




191:select week(order_date),
    avg(tip_amount)
from foodnest_delivery 
where priority_flag = 'Yes'
group  by week(order_date)
order by avg(tip_amount) desc
limit 1



192: SELECT 
    cuisine_type,
    COUNT(CASE WHEN discount_applied > 20 THEN 1 END) * 100.0 / COUNT(*) AS discount_percentage                (help to calculate order percent)
FROM 
    foodnest_delivery
WHERE 
    order_status = 'Delivered'
GROUP BY 
    cuisine_type
ORDER BY 
    discount_percentage DESC
    limit 1;



193:select delivery_agent,
        sum(order_value)
from foodnest_delivery
where repeat_customer='Yes'
group by delivery_agent
order by sum(order_value) desc
limit 4




194:select dayofweek(order_date),
count(*)
from foodnest_delivery
where order_status='Cancelled'
group by dayofweek(order_date)
order by count(*) desc
limit 1




195:select week(order_date),
    avg(order_value)
from foodnest_delivery
where repeat_customer='Yes'
group by week(order_date)
order by avg(order_value) desc
limit 1



196:SELECT 
    EXTRACT(WEEK FROM Order_Date) AS Week_Number,
    COUNT(CASE WHEN Feedback_Length > 30 THEN 1 END) * 100.0 / COUNT(*) AS Percentage_Feedback_Greater_Than_30
FROM 
    foodnest_delivery
GROUP BY 
    Week_Number
ORDER BY 
    Percentage_Feedback_Greater_Than_30 DESC
LIMIT 1;





197:select platform,
        week(order_date),
        sum(order_value) as total,
        avg(tip_amount) as totaltip
from foodnest_delivery 
group by platform, week(order_date)



198: select dayofweek(order_date),
count(*)
from foodnest_delivery
where repeat_customer='No'
group  by dayofweek(order_date)
order by count(*) desc, dayofweek(order_date) asc
limit 4






199: select dayofweek(order_date),
sum(tip_amount)/sum(order_value) as c
from foodnest_delivery
group by dayofweek(order_date)
order by c desc
limit 1


200: Select order_date,
sum(Order_Value)-coalesce(lag(sum(Order_Value)) over(order by order_date ),0) as revenue_growth
from foodnest_delivery 
group by order_date
order by revenue_growth desc limit 5;                        (Got help regarding how to use coalesce)




















    












